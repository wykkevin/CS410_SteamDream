{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG-3vJi392Th",
        "outputId": "da9744f3-c784-427e-9f99-8975cc0429dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY-jzt-h9R0n",
        "outputId": "7642fed8-9daa-48f0-d10f-faa8c9fccbb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1151433, 21)\n",
            "Index(['Unnamed: 0', 'recommendationid', 'language', 'review',\n",
            "       'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up',\n",
            "       'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase',\n",
            "       'received_for_free', 'written_during_early_access', 'author.steamid',\n",
            "       'author.num_games_owned', 'author.num_reviews',\n",
            "       'author.playtime_forever', 'author.playtime_last_two_weeks',\n",
            "       'author.playtime_at_review', 'author.last_played'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = './drive/MyDrive/Colab Notebooks/CS410/data/merged.csv'\n",
        "\n",
        "steam_data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "# steam_data.head()\n",
        "print(steam_data.shape)\n",
        "print(steam_data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnC_OwkYQ068"
      },
      "source": [
        "# Data Shuffle and Re-sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77OZV1koQzb5",
        "outputId": "cb262442-aeb5-4436-bb3d-b9afa119e5c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11514, 21)\n"
          ]
        }
      ],
      "source": [
        "steam_shuffled = steam_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "steam_shuffled = steam_shuffled.sample(frac=0.01).reset_index(drop=True)\n",
        "print(steam_shuffled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spm4l2JqUluw"
      },
      "source": [
        "# Label the data with sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg93wiFN-Unp",
        "outputId": "f7b9af6f-c830-4b20-d5ba-744f0cde17a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                              review  voted_up  sentiment\n",
              " 0                              is good gamei like it      True          1\n",
              " 1  It's definitely a game to play. It's one of th...      True          1\n",
              " 2             online jank as shit, but it's aoe2 yo.      True          1\n",
              " 3  This game is very immersive and allows many si...      True          1\n",
              " 4  Everyone posts negative hate against this game...      True          1,\n",
              " 1    6281\n",
              " 0    5233\n",
              " Name: sentiment, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "steam_filtered = steam_shuffled\n",
        "\n",
        "# Assign labels to the reviews (1 for positive and 0 for negative)\n",
        "steam_filtered['sentiment'] = (steam_data['voted_up'] == True).astype(int)\n",
        "\n",
        "# Display the distribution of the sentiments and the first few rows of the new dataframe\n",
        "sentiment_distribution = steam_filtered['sentiment'].value_counts()\n",
        "steam_filtered[['review', 'voted_up', 'sentiment']].head(), sentiment_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApO716xyUppK"
      },
      "source": [
        "# Preprocess the text and create training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjQe8KqBc2M3",
        "outputId": "b32b1292-a03e-40ea-bc97-8f7609957512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Download stopwords from NLTK\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to preprocess the text\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    # Stem the words\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OXUgUMYD-Zos"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Apply the preprocessing function to the review texts\n",
        "steam_filtered['review'] = steam_filtered['review'].apply(preprocess_text)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    steam_filtered['review'],\n",
        "    steam_filtered['sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "trained_models = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GQjYJFmuUhp",
        "outputId": "5cb8fd3c-8ae8-459c-c9bb-8c827da26883"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                              review  voted_up  sentiment\n",
              " 0                                    good gamei like      True          1\n",
              " 1  definit game play one best game excit detail c...      True          1\n",
              " 2                             onlin jank shit aoe yo      True          1\n",
              " 3  game immers allow mani simul game also allow p...      True          1\n",
              " 4  everyon post negat hate game yet still alpha b...      True          1,\n",
              " 1    6281\n",
              " 0    5233\n",
              " Name: sentiment, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "steam_filtered[['review', 'voted_up', 'sentiment']].head(), sentiment_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWrmPMnGqLRF"
      },
      "source": [
        "# Calculate most common words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsg-mSxOsWIK",
        "outputId": "45de1c21-22f2-4c0b-92d8-27ee1f54dea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top words indicating Positive sentiment with frequency percentage:\n",
            "game: Count - 10805, Percentage - 5.36%\n",
            "play: Count - 2902, Percentage - 1.44%\n",
            "get: Count - 2153, Percentage - 1.07%\n",
            "like: Count - 1984, Percentage - 0.98%\n",
            "time: Count - 1507, Percentage - 0.75%\n",
            "good: Count - 1433, Percentage - 0.71%\n",
            "fun: Count - 1342, Percentage - 0.67%\n",
            "dont: Count - 1165, Percentage - 0.58%\n",
            "even: Count - 1103, Percentage - 0.55%\n",
            "one: Count - 1088, Percentage - 0.54%\n",
            "make: Count - 1072, Percentage - 0.53%\n",
            "realli: Count - 1014, Percentage - 0.50%\n",
            "still: Count - 955, Percentage - 0.47%\n",
            "would: Count - 901, Percentage - 0.45%\n",
            "great: Count - 867, Percentage - 0.43%\n",
            "hour: Count - 848, Percentage - 0.42%\n",
            "much: Count - 825, Percentage - 0.41%\n",
            "buy: Count - 783, Percentage - 0.39%\n",
            "go: Count - 773, Percentage - 0.38%\n",
            "want: Count - 760, Percentage - 0.38%\n",
            "\n",
            "Top words indicating Negative sentiment with frequency percentage:\n",
            "game: Count - 9327, Percentage - 5.32%\n",
            "play: Count - 2342, Percentage - 1.34%\n",
            "like: Count - 1833, Percentage - 1.05%\n",
            "get: Count - 1734, Percentage - 0.99%\n",
            "time: Count - 1298, Percentage - 0.74%\n",
            "good: Count - 1221, Percentage - 0.70%\n",
            "fun: Count - 1143, Percentage - 0.65%\n",
            "dont: Count - 1043, Percentage - 0.59%\n",
            "even: Count - 992, Percentage - 0.57%\n",
            "one: Count - 954, Percentage - 0.54%\n",
            "realli: Count - 895, Percentage - 0.51%\n",
            "make: Count - 881, Percentage - 0.50%\n",
            "would: Count - 774, Percentage - 0.44%\n",
            "hour: Count - 742, Percentage - 0.42%\n",
            "great: Count - 717, Percentage - 0.41%\n",
            "still: Count - 710, Percentage - 0.41%\n",
            "buy: Count - 685, Percentage - 0.39%\n",
            "thing: Count - 677, Percentage - 0.39%\n",
            "go: Count - 677, Percentage - 0.39%\n",
            "much: Count - 674, Percentage - 0.38%\n",
            "\n",
            "Top words in the entire dataset with frequency percentage:\n",
            "game: Count - 20132, Percentage - 5.34%\n",
            "play: Count - 5244, Percentage - 1.39%\n",
            "get: Count - 3887, Percentage - 1.03%\n",
            "like: Count - 3817, Percentage - 1.01%\n",
            "time: Count - 2805, Percentage - 0.74%\n",
            "good: Count - 2654, Percentage - 0.70%\n",
            "fun: Count - 2485, Percentage - 0.66%\n",
            "dont: Count - 2208, Percentage - 0.59%\n",
            "even: Count - 2095, Percentage - 0.56%\n",
            "one: Count - 2042, Percentage - 0.54%\n",
            "make: Count - 1953, Percentage - 0.52%\n",
            "realli: Count - 1909, Percentage - 0.51%\n",
            "would: Count - 1675, Percentage - 0.44%\n",
            "still: Count - 1665, Percentage - 0.44%\n",
            "hour: Count - 1590, Percentage - 0.42%\n",
            "great: Count - 1584, Percentage - 0.42%\n",
            "much: Count - 1499, Percentage - 0.40%\n",
            "buy: Count - 1468, Percentage - 0.39%\n",
            "go: Count - 1450, Percentage - 0.38%\n",
            "thing: Count - 1421, Percentage - 0.38%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Assuming you have a DataFrame 'steam_filtered' with 'review' and 'sentiment' columns\n",
        "N_WORDS = 20\n",
        "# Function to get top words for a specific sentiment\n",
        "def get_top_words(df, sentiment_value=None):\n",
        "    if sentiment_value is not None:\n",
        "        df = df[df['sentiment'] == sentiment_value]\n",
        "    reviews = ' '.join(df['review'].values)  # Merge all reviews into one string\n",
        "    words_list = word_tokenize(reviews)  # Tokenize the merged string\n",
        "    word_counts = Counter(words_list)\n",
        "    total_words = sum(word_counts.values())\n",
        "    top_words = word_counts.most_common(N_WORDS)\n",
        "\n",
        "    top_words_with_percentage = []\n",
        "    for word, count in top_words:\n",
        "        frequency_percentage = (count / total_words) * 100\n",
        "        top_words_with_percentage.append((word, count, frequency_percentage))\n",
        "\n",
        "    return top_words_with_percentage\n",
        "\n",
        "# Calculate top words with frequency percentage for negative (sentiment = 0), positive (sentiment = 1), and all reviews\n",
        "top_negative_words = get_top_words(steam_filtered, 0)\n",
        "top_positive_words = get_top_words(steam_filtered, 1)\n",
        "top_all_words = get_top_words(steam_filtered)\n",
        "\n",
        "print(\"\\nTop words indicating Positive sentiment with frequency percentage:\")\n",
        "for word, count, percentage in top_positive_words:\n",
        "    print(f\"{word}: Count - {count}, Percentage - {percentage:.2f}%\")\n",
        "\n",
        "print(\"\\nTop words indicating Negative sentiment with frequency percentage:\")\n",
        "for word, count, percentage in top_negative_words:\n",
        "    print(f\"{word}: Count - {count}, Percentage - {percentage:.2f}%\")\n",
        "\n",
        "print(\"\\nTop words in the entire dataset with frequency percentage:\")\n",
        "for word, count, percentage in top_all_words:\n",
        "    print(f\"{word}: Count - {count}, Percentage - {percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld1n_qiLU29x"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm8PXCSJU7KL"
      },
      "source": [
        "## MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfqUVaSA-sSM",
        "outputId": "a5200b26-3563-438c-9dda-023d3fb60b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5223621363438993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.46      0.46      1048\n",
            "           1       0.56      0.58      0.57      1255\n",
            "\n",
            "    accuracy                           0.52      2303\n",
            "   macro avg       0.52      0.52      0.52      2303\n",
            "weighted avg       0.52      0.52      0.52      2303\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming X_train and y_train are training data and labels,\n",
        "# and X_test and y_test are testing data and labels.\n",
        "\n",
        "# Initialize the TfidfVectorizer with n-gram range\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the training data and transform the testing data\n",
        "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
        "x_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
        "\n",
        "# Initialize the MLPClassifier\n",
        "mlp_model = MLPClassifier(random_state=42)\n",
        "\n",
        "# Train the model with the training data\n",
        "mlp_model.fit(x_train_tfidf, y_train)\n",
        "\n",
        "# Predict the sentiments for the test data\n",
        "y_pred = mlp_model.predict(x_test_tfidf)\n",
        "\n",
        "# Calculate the accuracy of the predictions and print the classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PckM7qKk_FGd",
        "outputId": "74b6c6ef-f829-4ee6-e679-4175001c35aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Preprocess the new sentence using the defined preprocess_text function\n",
        "text = \"\"\"\n",
        "The game sucks\n",
        "\"\"\"\n",
        "new_sentence_to_predict = preprocess_text(text)\n",
        "\n",
        "# Transform the preprocessed sentence to TF-IDF vector using the fitted tfidf_vectorizer\n",
        "new_sentence_tfidf = tfidf_vectorizer.transform([new_sentence_to_predict])\n",
        "\n",
        "# Predict the sentiment using the trained MLP model\n",
        "new_sentence_pred = mlp_model.predict(new_sentence_tfidf)\n",
        "\n",
        "# Output the prediction (1 for positive, 0 for negative)\n",
        "predicted_sentiment = \"Positive\" if new_sentence_pred[0] == 1 else \"Negative\"\n",
        "predicted_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"\"\"\n",
        "The game is great\n",
        "\"\"\"\n",
        "new_sentence_to_predict2 = preprocess_text(text2)\n",
        "\n",
        "# Transform the preprocessed sentence to TF-IDF vector using the fitted tfidf_vectorizer\n",
        "new_sentence_tfidf2 = tfidf_vectorizer.transform([new_sentence_to_predict2])\n",
        "\n",
        "# Predict the sentiment using the trained MLP model\n",
        "new_sentence_pred2 = mlp_model.predict(new_sentence_tfidf2)\n",
        "\n",
        "# Output the prediction (1 for positive, 0 for negative)\n",
        "predicted_sentiment2 = \"Positive\" if new_sentence_pred2[0] == 1 else \"Negative\"\n",
        "predicted_sentiment2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XGgaUrZ9eED9",
        "outputId": "beef329c-b1a3-4622-8bbf-219721f5424e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo7dIKOl-1MM"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJS0LPam-2_s",
        "outputId": "a6f9f0d1-a912-408a-83c8-50f37cfd4611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 64)           640000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 196, 128)          41088     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 682389 (2.60 MB)\n",
            "Trainable params: 682389 (2.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "288/288 [==============================] - 21s 70ms/step - loss: 0.6907 - accuracy: 0.5372 - val_loss: 0.6899 - val_accuracy: 0.5449\n",
            "Epoch 2/10\n",
            "288/288 [==============================] - 20s 69ms/step - loss: 0.6806 - accuracy: 0.5685 - val_loss: 0.6904 - val_accuracy: 0.5462\n",
            "Epoch 3/10\n",
            "288/288 [==============================] - 32s 110ms/step - loss: 0.6048 - accuracy: 0.6719 - val_loss: 0.7274 - val_accuracy: 0.4846\n",
            "Epoch 4/10\n",
            "288/288 [==============================] - 37s 128ms/step - loss: 0.3980 - accuracy: 0.7944 - val_loss: 0.8159 - val_accuracy: 0.5132\n",
            "Epoch 5/10\n",
            "288/288 [==============================] - 23s 79ms/step - loss: 0.2129 - accuracy: 0.9071 - val_loss: 1.0556 - val_accuracy: 0.5137\n",
            "Epoch 6/10\n",
            "288/288 [==============================] - 20s 70ms/step - loss: 0.1455 - accuracy: 0.9331 - val_loss: 1.2643 - val_accuracy: 0.5289\n",
            "Epoch 7/10\n",
            "288/288 [==============================] - 20s 68ms/step - loss: 0.1150 - accuracy: 0.9428 - val_loss: 1.4446 - val_accuracy: 0.5176\n",
            "Epoch 8/10\n",
            "288/288 [==============================] - 20s 70ms/step - loss: 0.0986 - accuracy: 0.9472 - val_loss: 1.5692 - val_accuracy: 0.5106\n",
            "Epoch 9/10\n",
            "288/288 [==============================] - 21s 72ms/step - loss: 0.0888 - accuracy: 0.9519 - val_loss: 1.7810 - val_accuracy: 0.5050\n",
            "Epoch 10/10\n",
            "288/288 [==============================] - 20s 71ms/step - loss: 0.0859 - accuracy: 0.9526 - val_loss: 1.9287 - val_accuracy: 0.5098\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def train_cnn_model():\n",
        "  # Parameters\n",
        "  vocab_size = 10000  # Adjust as necessary\n",
        "  embedding_dim = 64  # Adjust as necessary\n",
        "  max_length = 200  # Should be close to the actual length of the preprocessed text\n",
        "  filter_sizes = 128  # The number of output filters in the convolution\n",
        "  kernel_size = 5  # The length of the convolution window\n",
        "\n",
        "  trunc_type='post'\n",
        "  padding_type='post'\n",
        "  oov_tok = \"<OOV>\"\n",
        "\n",
        "  # Tokenize and pad sequences\n",
        "  tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "  tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "  word_index = tokenizer.word_index\n",
        "  train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "  train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "  validation_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "  validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n",
        "  # Define the CNN model\n",
        "  cnn_model = Sequential([\n",
        "      Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "      Conv1D(filter_sizes, kernel_size, activation='relu'),\n",
        "      GlobalMaxPooling1D(),\n",
        "      Dense(10, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(1, activation='sigmoid')  # Use 'softmax' for multi-class classification\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  cnn_model.compile(loss='binary_crossentropy',  # Or 'categorical_crossentropy' for a multi-class problem\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Summary of the model\n",
        "  cnn_model.summary()\n",
        "\n",
        "  # Train the model\n",
        "  num_epochs = 10\n",
        "  history = cnn_model.fit(train_padded, y_train,\n",
        "                      epochs=num_epochs,\n",
        "                      validation_data=(validation_padded, y_test))\n",
        "\n",
        "  return cnn_model\n",
        "\n",
        "cnn_model = train_cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl1WVAKJAR-L"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iEHtHhRYATYk",
        "outputId": "c7eb8570-2c62-4e2e-86fb-45325fb03f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 64)           640000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 200, 64)           33024     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200, 64)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                792       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 686257 (2.62 MB)\n",
            "Trainable params: 686257 (2.62 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "288/288 [==============================] - 101s 328ms/step - loss: 0.6898 - accuracy: 0.5434 - val_loss: 0.6896 - val_accuracy: 0.5449\n",
            "Epoch 2/10\n",
            "288/288 [==============================] - 86s 299ms/step - loss: 0.6890 - accuracy: 0.5481 - val_loss: 0.6894 - val_accuracy: 0.5441\n",
            "Epoch 3/10\n",
            "288/288 [==============================] - 84s 292ms/step - loss: 0.6823 - accuracy: 0.5569 - val_loss: 0.6981 - val_accuracy: 0.5419\n",
            "Epoch 4/10\n",
            "288/288 [==============================] - 86s 297ms/step - loss: 0.6784 - accuracy: 0.5584 - val_loss: 0.6970 - val_accuracy: 0.5436\n",
            "Epoch 5/10\n",
            "288/288 [==============================] - 87s 303ms/step - loss: 0.6722 - accuracy: 0.5597 - val_loss: 0.7164 - val_accuracy: 0.5449\n",
            "Epoch 6/10\n",
            "288/288 [==============================] - 87s 301ms/step - loss: 0.6702 - accuracy: 0.5598 - val_loss: 0.7240 - val_accuracy: 0.5432\n",
            "Epoch 7/10\n",
            "288/288 [==============================] - 90s 313ms/step - loss: 0.6692 - accuracy: 0.5599 - val_loss: 0.7177 - val_accuracy: 0.5436\n",
            "Epoch 8/10\n",
            "235/288 [=======================>......] - ETA: 16s - loss: 0.6714 - accuracy: 0.5608"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ee9b846171af>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-ee9b846171af>\u001b[0m in \u001b[0;36mtrain_lstm_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   history = model.fit(train_padded, y_train,\n\u001b[0m\u001b[1;32m     49\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                       validation_data=(validation_padded, y_test))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def train_lstm_model():\n",
        "  # Parameters\n",
        "  vocab_size = 10000  # This should be adjusted to the size of your vocabulary\n",
        "  embedding_dim = 64  # This can be tuned\n",
        "  max_length = 200  # This should be set to the length that covers most of the data or based on exploratory analysis\n",
        "  trunc_type='post'\n",
        "  padding_type='post'\n",
        "  oov_tok = \"<OOV>\"\n",
        "\n",
        "  # Tokenize and pad sequences\n",
        "  tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "  tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "  word_index = tokenizer.word_index\n",
        "  train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "  train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "  validation_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "  validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "  # Define the LSTM model\n",
        "  model = Sequential([\n",
        "      Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "      LSTM(64, return_sequences=True),\n",
        "      Dropout(0.2),\n",
        "      LSTM(32),\n",
        "      Dense(24, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(1, activation='sigmoid')  # Use 'softmax' for multiclass classification\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multiclass classification\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Summary of the model\n",
        "  model.summary()\n",
        "\n",
        "  # Train the model\n",
        "  num_epochs = 10\n",
        "  history = model.fit(train_padded, y_train,\n",
        "                      epochs=num_epochs,\n",
        "                      validation_data=(validation_padded, y_test))\n",
        "\n",
        "  return model\n",
        "\n",
        "lstm_model = train_lstm_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkSnuBwX2VE9"
      },
      "source": [
        "## Logistic Regression, SVM,  Naive Bayes Classifier, LinearSVC, RandomForestClassifier, XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD-s2PNd2aB3"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def train_and_evaluate_classifiers(x_train, y_train, x_test, y_test):\n",
        "    classifiers = {\n",
        "        'SVM': SVC(kernel='linear'),\n",
        "        'LogisticRegression': LogisticRegression(),\n",
        "        'NaiveBayes': MultinomialNB(),\n",
        "        'LinearSVC': LinearSVC(),\n",
        "        'RandomForest': RandomForestClassifier(),\n",
        "        'XGBoost': XGBClassifier(),\n",
        "        'GradientBoosting': GradientBoostingClassifier(),\n",
        "        'AdaBoost': AdaBoostClassifier(),\n",
        "        'DecisionTree': DecisionTreeClassifier(),\n",
        "        'KNN': KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    trained_classifiers = {}\n",
        "\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        text_clf = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer()),\n",
        "            ('clf', clf)\n",
        "        ])\n",
        "        text_clf.fit(x_train, y_train)\n",
        "        trained_classifiers[clf_name] = text_clf\n",
        "\n",
        "        predicted = text_clf.predict(x_test)\n",
        "\n",
        "        print(f\"Classifier: {clf_name}\")\n",
        "        print(classification_report(y_test, predicted))\n",
        "        print(f\"Accuracy: {accuracy_score(y_test, predicted)}\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "    return trained_classifiers\n",
        "\n",
        "# Usage example:\n",
        "\n",
        "# Assuming x_train, y_train, x_test, y_test are defined\n",
        "sklearn_trained_models = train_and_evaluate_classifiers(x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpYqAuEC6pjb"
      },
      "outputs": [],
      "source": [
        "# Use a trained model for prediction\n",
        "trained_models.update(sklearn_trained_models)\n",
        "trained_models['MLP'] = mlp_model\n",
        "trained_models['CNN'] = cnn_model\n",
        "trained_models['LSTM'] = lstm_model\n",
        "\n",
        "MAX_LENGTH = 200  # Should be close to the actual length of the preprocessed text\n",
        "TRUNC_TYPE='post'\n",
        "PADDING_TYPE='post'\n",
        "\n",
        "new_text = \"The game sucks\"\n",
        "preprocessed_text = preprocess_text(new_text)  # preprocess_text is your custom preprocessing function\n",
        "\n",
        "# Choose a model for prediction (e.g., SVM as an example)\n",
        "tempting_models = ['SVM', 'LogisticRegression', 'NaiveBayes', 'LinearSVC', 'RandomForest', 'XGBoost',\n",
        "                   'GradientBoosting', 'AdaBoost', 'DecisionTree', 'KNN', 'MLP']\n",
        "\n",
        "sentiment_labels = []\n",
        "\n",
        "for model in tempting_models:\n",
        "\n",
        "  if model == 'MLP':\n",
        "    # Transform the preprocessed sentence to TF-IDF vector using the fitted tfidf_vectorizer\n",
        "    new_sentence_tfidf = tfidf_vectorizer.transform([preprocessed_text])\n",
        "\n",
        "    # Predict the sentiment using the trained MLP model\n",
        "    predicted_sentiment = mlp_model.predict(new_sentence_tfidf)\n",
        "\n",
        "  # elif model == 'CNN':\n",
        "  #   # Convert the text to a sequence\n",
        "  #   input_sequence = tokenizer.texts_to_sequences([preprocessed_text])\n",
        "\n",
        "  #   # Pad the sequence\n",
        "  #   input_padded = pad_sequences(input_sequence, maxlen=MAX_LENGTH, padding=TRUNC_TYPE, truncating=PADDING_TYPE)\n",
        "\n",
        "  #   # Predict the sentiment\n",
        "  #   prediction = model.predict(input_padded)\n",
        "\n",
        "  #   # Interpret the output\n",
        "  #   # Since it's a binary classification, we can use 0.5 as a threshold to interpret the sentiment\n",
        "  #   sentiment_labels = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n",
        "\n",
        "  else:\n",
        "\n",
        "    selected_model = trained_models[model]\n",
        "    predicted_sentiment = selected_model.predict([preprocessed_text])\n",
        "\n",
        "    sentiment_label = 'positive' if predicted_sentiment[0] == 1 else 'negative'\n",
        "\n",
        "\n",
        "  print(f\"The predicted sentiment for '{new_text}' using {model} is '{sentiment_label}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki9y0CNwfbfZ"
      },
      "outputs": [],
      "source": [
        "def contains_no_letters(text):\n",
        "   # Check if the text contains no letters\n",
        "   return not any(char.isalpha() for char in text)\n",
        "   # Remove rows with no letters in 'review'\n",
        "   df = df[~df['review'].apply(contains_no_letters)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K7FY3BZ-CGG"
      },
      "source": [
        "Model for Votes Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNlhY8f1-HpF",
        "outputId": "8bd08268-134b-47c1-c837-10307b4ae93d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                              review  votes_up  useful\n",
              " 0                                    good gamei like         0       0\n",
              " 1  definit game play one best game excit detail c...         0       0\n",
              " 2                             onlin jank shit aoe yo         0       0\n",
              " 3  game immers allow mani simul game also allow p...         0       0\n",
              " 4  everyon post negat hate game yet still alpha b...         1       0,\n",
              " 0    10636\n",
              " 1      878\n",
              " Name: useful, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.count_nonzero(steam_filtered['votes_up'])\n",
        "np.sum(steam_filtered['votes_up'] > 0)\n",
        "\n",
        "# Divide votes_up into two cases (1 for >=5 and 0 for <5)\n",
        "steam_filtered['useful'] = (steam_data['votes_up'] >= 5).astype(int)\n",
        "\n",
        "# Display the distribution of the sentiments and the first few rows of the new dataframe\n",
        "sentiment_distribution = steam_filtered['useful'].value_counts()\n",
        "steam_filtered[['review', 'votes_up', 'useful']].head(), sentiment_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CMaxB9MWY9ts"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and test sets\n",
        "x_useful_train, x_useful_test, y_useful_train, y_useful_test = train_test_split(\n",
        "    steam_filtered['review'],\n",
        "    steam_filtered['useful'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTcP-YPZZnbU"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming X_train and y_train are training data and labels,\n",
        "# and X_test and y_test are testing data and labels.\n",
        "\n",
        "# Initialize the TfidfVectorizer with n-gram range\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the training data and transform the testing data\n",
        "x_useful_train_tfidf = tfidf_vectorizer.fit_transform(x_useful_train)\n",
        "x_useful_test_tfidf = tfidf_vectorizer.transform(x_useful_test)\n",
        "\n",
        "# Initialize the MLPClassifier\n",
        "mlp_useful_model = MLPClassifier(random_state=42)\n",
        "\n",
        "# Train the model with the training data\n",
        "mlp_useful_model.fit(x_useful_train_tfidf, y_useful_train)\n",
        "\n",
        "# Predict the sentiments for the test data\n",
        "y_useful_pred = mlp_useful_model.predict(x_useful_test_tfidf)\n",
        "\n",
        "# Calculate the accuracy of the predictions and print the classification report\n",
        "useful_accuracy = accuracy_score(y_useful_test, y_useful_pred)\n",
        "useful_report = classification_report(y_useful_test, y_useful_pred)\n",
        "\n",
        "print(f\"Accuracy: {useful_accuracy}\")\n",
        "print(useful_report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDwwyjvocj75"
      },
      "outputs": [],
      "source": [
        "# Preprocess the new sentence using the defined preprocess_text function\n",
        "useful_text = \"\"\"\n",
        "The game sucks\n",
        "\"\"\"\n",
        "new_sentence_to_predict_useful = preprocess_text(useful_text)\n",
        "\n",
        "# Transform the preprocessed sentence to TF-IDF vector using the fitted tfidf_vectorizer\n",
        "new_useful_sentence_tfidf = tfidf_vectorizer.transform([new_sentence_to_predict_useful])\n",
        "\n",
        "# Predict the sentiment using the trained MLP model\n",
        "new_useful_sentence_pred = mlp_useful_model.predict(new_useful_sentence_tfidf)\n",
        "\n",
        "# Output the prediction (1 for positive, 0 for negative)\n",
        "predicted_useful_sentiment = \"Positive\" if new_useful_sentence_pred[0] == 1 else \"Negative\"\n",
        "predicted_useful_sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoaLIxtldLrL"
      },
      "source": [
        "Model for Votes Funny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYKBIeY3dIjP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.count_nonzero(steam_filtered['votes_funny'])\n",
        "np.sum(steam_filtered['votes_funny'] > 0)\n",
        "\n",
        "# Divide votes_up into two cases (1 for >=5 and 0 for <5)\n",
        "steam_filtered['isFunny'] = (steam_data['votes_funny'] >= 5).astype(int)\n",
        "\n",
        "# Display the distribution of the sentiments and the first few rows of the new dataframe\n",
        "sentiment_distribution = steam_filtered['isFunny'].value_counts()\n",
        "steam_filtered[['review', 'votes_funny', 'isFunny']].head(), sentiment_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRKhNAXhdW9X"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and test sets\n",
        "x_funny_train, x_funny_test, y_funny_train, y_funny_test = train_test_split(\n",
        "    steam_filtered['review'],\n",
        "    steam_filtered['isFunny'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci9y9yDBdgp7"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming X_train and y_train are training data and labels,\n",
        "# and X_test and y_test are testing data and labels.\n",
        "\n",
        "# Initialize the TfidfVectorizer with n-gram range\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the training data and transform the testing data\n",
        "x_funny_train_tfidf = tfidf_vectorizer.fit_transform(x_funny_train)\n",
        "x_funny_test_tfidf = tfidf_vectorizer.transform(x_funny_test)\n",
        "\n",
        "# Initialize the MLPClassifier\n",
        "mlp_funny_model = MLPClassifier(random_state=42)\n",
        "\n",
        "# Train the model with the training data\n",
        "mlp_funny_model.fit(x_funny_train_tfidf, y_funny_train)\n",
        "\n",
        "# Predict the sentiments for the test data\n",
        "y_funny_pred = mlp_funny_model.predict(x_funny_test_tfidf)\n",
        "\n",
        "# Calculate the accuracy of the predictions and print the classification report\n",
        "funny_accuracy = accuracy_score(y_funny_test, y_funny_pred)\n",
        "funny_report = classification_report(y_funny_test, y_funny_pred)\n",
        "\n",
        "print(f\"Accuracy: {funny_accuracy}\")\n",
        "print(funny_report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4S6-dtHdx_9"
      },
      "outputs": [],
      "source": [
        "# Preprocess the new sentence using the defined preprocess_text function\n",
        "funny_text = \"\"\"\n",
        "The game sucks\n",
        "\"\"\"\n",
        "new_sentence_to_predict_funny = preprocess_text(funny_text)\n",
        "\n",
        "# Transform the preprocessed sentence to TF-IDF vector using the fitted tfidf_vectorizer\n",
        "new_funny_sentence_tfidf = tfidf_vectorizer.transform([new_sentence_to_predict_funny])\n",
        "\n",
        "# Predict the sentiment using the trained MLP model\n",
        "new_funny_sentence_pred = mlp_funny_model.predict(new_funny_sentence_tfidf)\n",
        "\n",
        "# Output the prediction (1 for positive, 0 for negative)\n",
        "predicted_funny_sentiment = \"Positive\" if new_funny_sentence_pred[0] == 1 else \"Negative\"\n",
        "predicted_funny_sentiment"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}